{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6b3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import contractions\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc564430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "783f8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14643, 27)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('D:/Python_Projects/spotivibe_exp/data.csv')\n",
    "audio_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa7470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           acousticness  danceability    energy  instrumentalness  liveness  \\\n",
      "mood_cats                                                                     \n",
      "0              0.008902      0.114597  0.032946         -0.107782  0.009064   \n",
      "1              0.071381     -0.075932 -0.126077          0.052655 -0.012502   \n",
      "2              0.160174      0.039954 -0.201839          0.056050 -0.067977   \n",
      "3             -0.267407     -0.091364  0.326379          0.012385  0.074780   \n",
      "\n",
      "           loudness  speechiness     tempo   valence  \n",
      "mood_cats                                             \n",
      "0          0.062197    -0.041869 -0.000305  0.203921  \n",
      "1         -0.089532    -0.031800 -0.014809 -0.148878  \n",
      "2         -0.148095    -0.045095 -0.052108 -0.060003  \n",
      "3          0.187450     0.139999  0.073110 -0.009197  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the audio features\n",
    "data[audio_features] = scaler.fit_transform(data[audio_features])\n",
    "\n",
    "# Group the data by label (assuming 'mood' is the label column) and calculate the mean of each feature\n",
    "mean_values_per_label = data.groupby('mood_cats')[audio_features].mean()\n",
    "\n",
    "# Display the mean values for each label\n",
    "print(mean_values_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f130a53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14613.00</td>\n",
       "      <td>14613.00</td>\n",
       "      <td>14613.00</td>\n",
       "      <td>14613.00</td>\n",
       "      <td>14613.00</td>\n",
       "      <td>14613.00</td>\n",
       "      <td>14613.00</td>\n",
       "      <td>14613.00</td>\n",
       "      <td>14613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.87</td>\n",
       "      <td>-3.19</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-6.95</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>-1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.15</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.98</td>\n",
       "      <td>6.88</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability    energy  instrumentalness  liveness  \\\n",
       "count      14613.00      14613.00  14613.00          14613.00  14613.00   \n",
       "mean          -0.00         -0.00     -0.00             -0.00     -0.00   \n",
       "std            1.00          1.00      1.00              1.00      1.00   \n",
       "min           -0.87         -3.19     -2.30             -0.60     -1.19   \n",
       "25%           -0.84         -0.66     -0.69             -0.60     -0.59   \n",
       "50%           -0.49          0.09      0.10             -0.60     -0.41   \n",
       "75%            0.73          0.73      0.81              0.28      0.31   \n",
       "max            2.15          2.19      1.61              2.29      5.45   \n",
       "\n",
       "       loudness  speechiness     tempo   valence  \n",
       "count  14613.00     14613.00  14613.00  14613.00  \n",
       "mean       0.00        -0.00      0.00     -0.00  \n",
       "std        1.00         1.00      1.00      1.00  \n",
       "min       -6.95        -0.90     -4.03     -1.79  \n",
       "25%       -0.33        -0.60     -0.82     -0.83  \n",
       "50%        0.24        -0.47     -0.04     -0.11  \n",
       "75%        0.65         0.09      0.65      0.76  \n",
       "max        1.98         6.88      3.21      2.19  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[audio_features].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d1f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acousticness       -0.005992\n",
      "danceability        0.007543\n",
      "energy             -0.001556\n",
      "instrumentalness   -0.055199\n",
      "liveness            0.006302\n",
      "loudness            0.023503\n",
      "speechiness         0.039845\n",
      "tempo              -0.024381\n",
      "valence            -0.012659\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert lyrics into TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['cleaned_lyrics']).toarray()\n",
    "\n",
    "# Step 2: Scale your audio features to 0-1 range using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "audio_features = data[['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', \n",
    "                     'loudness', 'speechiness', 'tempo', 'valence']]\n",
    "\n",
    "# Handle missing or constant values (fill missing with 0, and check variance)\n",
    "audio_features = audio_features.fillna(0)\n",
    "\n",
    "# Scale the audio features\n",
    "scaled_audio_features = scaler.fit_transform(audio_features)\n",
    "\n",
    "# Step 3: Correlation Analysis\n",
    "# Compute correlation between each audio feature and the mean of TF-IDF vectors\n",
    "tfidf_mean = np.mean(tfidf_features, axis=1)\n",
    "\n",
    "# Check if TF-IDF mean has constant values (if so, correlation is not meaningful)\n",
    "if np.std(tfidf_mean) == 0:\n",
    "    print(\"TF-IDF mean vector has constant values. Correlation may not be meaningful.\")\n",
    "else:\n",
    "    # Calculate correlation, handle constant columns\n",
    "    correlations = pd.DataFrame(scaled_audio_features, columns=audio_features.columns).apply(\n",
    "        lambda col: np.corrcoef(col, tfidf_mean)[0, 1] if np.std(col) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "# Display correlations\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade23a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train before removing NaNs: (11714, 209)\n",
      "Shape of X_train after removing NaNs: (11688, 209)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.44      0.49       840\n",
      "           1       0.48      0.68      0.57       779\n",
      "           2       0.98      0.82      0.89       630\n",
      "           3       0.99      0.94      0.96       676\n",
      "\n",
      "    accuracy                           0.70      2925\n",
      "   macro avg       0.75      0.72      0.73      2925\n",
      "weighted avg       0.73      0.70      0.71      2925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_lyrics'], data['mood_cats'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 1: Process text-based features (TF-IDF for lyrics)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=200)  # Example using 1-grams and 2-grams\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Step 2: Process audio features (scaling them between 0 and 1)\n",
    "audio_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the audio features\n",
    "X_train_audio = scaler.fit_transform(data.loc[X_train.index, audio_features])\n",
    "X_test_audio = scaler.transform(data.loc[X_test.index, audio_features])\n",
    "\n",
    "\n",
    "audio_weight = 10  # Increase this factor to give more weight to audio features\n",
    "X_train_combined = np.hstack([X_train_tfidf.toarray(), X_train_audio * audio_weight])\n",
    "X_test_combined = np.hstack([X_test_tfidf.toarray(), X_test_audio * audio_weight])\n",
    "\n",
    "# Step 1: Find the rows with NaN values in training and test sets\n",
    "nan_rows_train = np.isnan(X_train_combined).any(axis=1)\n",
    "nan_rows_test = np.isnan(X_test_combined).any(axis=1)\n",
    "\n",
    "# Step 2: Drop the rows with NaN values in the audio features\n",
    "X_train = X_train_combined[~nan_rows_train]\n",
    "X_test= X_test_combined[~nan_rows_test]\n",
    "\n",
    "# Also drop corresponding rows in y_train and y_test\n",
    "y_train = y_train[~nan_rows_train]\n",
    "y_test = y_test[~nan_rows_test]\n",
    "\n",
    "# Display the shapes after dropping NaN rows\n",
    "print(f\"Shape of X_train before removing NaNs: {X_train_combined.shape}\")\n",
    "print(f\"Shape of X_train after removing NaNs: {X_train.shape}\")\n",
    "\n",
    "\n",
    "# Step 4: Train the SVM model on the combined feature set\n",
    "\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)  # Adjust parameters as needed\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions and evaluate the model\n",
    "y_pred = svc_model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7615a7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.47      0.49       842\n",
      "           1       0.46      0.60      0.52       779\n",
      "           2       0.99      0.83      0.90       632\n",
      "           3       1.00      0.94      0.97       676\n",
      "\n",
      "    accuracy                           0.69      2929\n",
      "   macro avg       0.74      0.71      0.72      2929\n",
      "weighted avg       0.72      0.69      0.70      2929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the dataset for text (TF-IDF) features\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(data['cleaned_lyrics'], data['mood_cats'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Vectorize text using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "# Step 3: Prepare and split audio features\n",
    "audio_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', \n",
    "                  'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "audio_features_data = data[audio_features]\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "audio_features_data_imputed = imputer.fit_transform(audio_features_data)\n",
    "\n",
    "# Split the imputed audio features and the labels\n",
    "X_train_audio, X_test_audio, y_train_audio, y_test_audio = train_test_split(\n",
    "    audio_features_data_imputed, data['mood_cats'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Train separate models\n",
    "# Model 1: SVM on TF-IDF features\n",
    "svc_text = SVC(kernel='rbf', C=10, gamma=1, probability=True)  # Use probability=True for voting\n",
    "svc_text.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Model 2: SVM on audio features\n",
    "svc_audio = SVC(kernel='rbf', C=10, gamma=1, probability=True)  # Use probability=True for voting\n",
    "svc_audio.fit(X_train_audio, y_train)\n",
    "\n",
    "# Step 5: Voting Classifier (Soft Voting)\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svc_text', svc_text),\n",
    "    ('svc_audio', svc_audio)\n",
    "], voting='soft')\n",
    "\n",
    "# Combine text (TF-IDF) and audio features\n",
    "X_train_combined = np.hstack([X_train_tfidf.toarray(), X_train_audio])\n",
    "X_test_combined = np.hstack([X_test_tfidf.toarray(), X_test_audio])\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Step 6: Make predictions and evaluate\n",
    "y_pred = voting_clf.predict(X_test_combined)\n",
    "\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b784354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
