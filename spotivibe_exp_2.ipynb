{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf210f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\melih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "print(\"GPU Available: \", torch.cuda.is_available())\n",
    "import contractions\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import BertTokenizer,BertModel, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.sparse import hstack\n",
    "from nltk import pos_tag\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae19207",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('D:/Python_Projects/spotivibe_exp/data.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_lyrics'], data['mood_cats'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe258a96",
   "metadata": {},
   "source": [
    "# Unigram + Bigram TFIDF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eef68554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer for Unigrams and Bigram\n",
    "bigram_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = bigram_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = bigram_vectorizer.transform(X_test)\n",
    "\n",
    "svc_model = SVC(kernel='rbf',C=10, gamma=1)\n",
    "y_pred_bigram = svc_model.predict(X_test_tfidf)\n",
    "print(\"Bigram Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3adcc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Word2Vec model (Google News, 300 dimensions)\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('D:/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "def get_average_word2vec(text, model, vector_size=300):\n",
    "    # Tokenize the text and calculate average word2vec for all valid words\n",
    "    words = text.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        # Return a vector of zeros if no valid words found\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Apply the function to the training and test sets\n",
    "X_train_w2v = np.array([get_average_word2vec(text, word2vec_model) for text in X_train])\n",
    "X_test_w2v = np.array([get_average_word2vec(text, word2vec_model) for text in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85c3b8",
   "metadata": {},
   "source": [
    "# Word2Vec SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1fc9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03       842\n",
      "           1       0.45      1.00      0.62       779\n",
      "           2       1.00      0.89      0.94       632\n",
      "           3       1.00      0.95      0.97       676\n",
      "\n",
      "    accuracy                           0.68      2929\n",
      "   macro avg       0.86      0.71      0.64      2929\n",
      "weighted avg       0.85      0.68      0.60      2929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained Word2Vec model (Google News, 300 dimensions)\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('D:/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "def get_average_word2vec(text, model, vector_size=300):\n",
    "    # Tokenize the text and calculate average word2vec for all valid words\n",
    "    words = text.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        # Return a vector of zeros if no valid words found\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Apply the function to the training and test sets\n",
    "X_train_w2v = np.array([get_average_word2vec(text, word2vec_model) for text in X_train])\n",
    "X_test_w2v = np.array([get_average_word2vec(text, word2vec_model) for text in X_test])\n",
    "\n",
    "# Standardize the Word2Vec embeddings\n",
    "scaler = StandardScaler()\n",
    "X_train_w2v_scaled = scaler.fit_transform(X_train_w2v)\n",
    "X_test_w2v_scaled = scaler.transform(X_test_w2v)\n",
    "\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svc_model.fit(X_train_w2v_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svc_model.predict(X_test_w2v_scaled)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d16fae",
   "metadata": {},
   "source": [
    "# NRClex Lexicons SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "171df653",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.40      0.41       842\n",
      "           1       0.30      0.67      0.42       779\n",
      "           2       0.67      0.01      0.02       632\n",
      "           3       0.48      0.24      0.32       676\n",
      "\n",
      "    accuracy                           0.35      2929\n",
      "   macro avg       0.46      0.33      0.29      2929\n",
      "weighted avg       0.45      0.35      0.31      2929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nrclex import NRCLex\n",
    "\n",
    "def get_emotion_scores(text):\n",
    "    emotion = NRCLex(text)\n",
    "    return emotion.raw_emotion_scores\n",
    "\n",
    "# Apply the function to get emotion scores for each lyric\n",
    "def extract_emotion_features(texts):\n",
    "    all_scores = []\n",
    "    for text in texts:\n",
    "        scores = get_emotion_scores(text)\n",
    "        # You can standardize or normalize the scores if needed\n",
    "        all_scores.append([scores.get('anger', 0), scores.get('fear', 0), scores.get('joy', 0), scores.get('sadness', 0)])\n",
    "    return np.array(all_scores)\n",
    "\n",
    "\n",
    "# Get emotion scores for training and test sets\n",
    "X_train_nrc = extract_emotion_features(X_train)\n",
    "X_test_nrc = extract_emotion_features(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_nrc_s = scaler.fit_transform(X_train_nrc)\n",
    "X_test_nrc_s = scaler.transform(X_test_nrc)\n",
    "\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svc_model.fit(X_train_nrc_s, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svc_model.predict(X_test_nrc_s)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f673d314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11714, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nrc_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a024da",
   "metadata": {},
   "source": [
    "# Unigram+Bigram TFIDF Combined Word2Vec SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77aaf1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62       770\n",
      "           1       0.67      0.00      0.00       819\n",
      "           2       1.00      0.91      0.95       671\n",
      "           3       1.00      0.94      0.97       687\n",
      "\n",
      "    accuracy                           0.69      2947\n",
      "   macro avg       0.78      0.71      0.64      2947\n",
      "weighted avg       0.76      0.69      0.61      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine the dense Word2Vec embeddings and sparse TF-IDF features\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_w2v_scaled])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_w2v_scaled])\n",
    "\n",
    "svc_model = SVC(kernel='rbf', C=50, gamma=1)\n",
    "svc_model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svc_model.predict(X_test_combined)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0b3ae",
   "metadata": {},
   "source": [
    "# LIWC, Unigram+Bigram TFIDF Combined Word2Vec SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30aada4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with LIWC-like Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55       770\n",
      "           1       0.55      0.57      0.56       819\n",
      "           2       0.98      0.91      0.94       671\n",
      "           3       0.99      0.94      0.96       687\n",
      "\n",
      "    accuracy                           0.73      2947\n",
      "   macro avg       0.76      0.75      0.76      2947\n",
      "weighted avg       0.75      0.73      0.74      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define LIWC-like categories\n",
    "pronouns = {'i', 'you', 'he', 'she', 'we', 'they'}\n",
    "function_words = {'the', 'and', 'but', 'or', 'so', 'because', 'when', 'although', 'if'}\n",
    "positive_emotions = {'happy', 'joy', 'love', 'great', 'wonderful', 'good'}\n",
    "negative_emotions = {'sad', 'angry', 'fear', 'hate', 'bad', 'terrible', 'worried'}\n",
    "\n",
    "def extract_liwc_features(text):\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    \n",
    "    # Initialize counters for each category\n",
    "    pronoun_count = 0\n",
    "    function_word_count = 0\n",
    "    positive_emotion_count = 0\n",
    "    negative_emotion_count = 0\n",
    "    \n",
    "    # Loop through each word in the text\n",
    "    for word in words:\n",
    "        word = word.lower()  # Normalize to lowercase\n",
    "        if word in pronouns:\n",
    "            pronoun_count += 1\n",
    "        if word in function_words:\n",
    "            function_word_count += 1\n",
    "        if word in positive_emotions:\n",
    "            positive_emotion_count += 1\n",
    "        if word in negative_emotions:\n",
    "            negative_emotion_count += 1\n",
    "    \n",
    "    # Calculate percentages relative to total word count\n",
    "    pronoun_percentage = pronoun_count / num_words if num_words > 0 else 0\n",
    "    function_word_percentage = function_word_count / num_words if num_words > 0 else 0\n",
    "    positive_emotion_percentage = positive_emotion_count / num_words if num_words > 0 else 0\n",
    "    negative_emotion_percentage = negative_emotion_count / num_words if num_words > 0 else 0\n",
    "    \n",
    "    # Return a feature vector\n",
    "    return np.array([num_words, pronoun_percentage, function_word_percentage, \n",
    "                     positive_emotion_percentage, negative_emotion_percentage])\n",
    "\n",
    "# Apply the function to the dataset\n",
    "X_train_liwc = np.array([extract_liwc_features(text) for text in X_train])\n",
    "X_test_liwc = np.array([extract_liwc_features(text) for text in X_test])\n",
    "\n",
    "# Combine TF-IDF features, Word2Vec features, and LIWC-like features\n",
    "X_train_combined = hstack([X_train_tfidf, np.hstack((X_train_w2v, X_train_liwc))])\n",
    "X_test_combined = hstack([X_test_tfidf, np.hstack((X_test_w2v, X_test_liwc))])\n",
    "\n",
    "# Train and evaluate the model\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svc_model.fit(X_train_combined, y_train)\n",
    "y_pred_combined = svc_model.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report with LIWC-like Features:\")\n",
    "print(classification_report(y_test, y_pred_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6379cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with LIWC-like Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.56       842\n",
      "           1       0.52      0.59      0.55       779\n",
      "           2       0.99      0.89      0.94       632\n",
      "           3       1.00      0.95      0.97       676\n",
      "\n",
      "    accuracy                           0.73      2929\n",
      "   macro avg       0.77      0.75      0.76      2929\n",
      "weighted avg       0.75      0.73      0.74      2929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define expanded LIWC-like categories\n",
    "pronouns = {'i', 'you', 'he', 'she', 'we', 'they', 'me', 'him', 'her', 'us', 'them'}\n",
    "function_words = {'the', 'and', 'but', 'or', 'so', 'because', 'when', 'although', 'if', 'a', 'an'}\n",
    "positive_emotions = {'happy', 'joy', 'love', 'great', 'wonderful', 'good', 'excited', 'delight', 'glad'}\n",
    "negative_emotions = {'sad', 'angry', 'fear', 'hate', 'bad', 'terrible', 'worried', 'anxious', 'upset'}\n",
    "cognitive_processes = {'think', 'know', 'believe', 'understand', 'realize', 'consider', 'decide', 'conclude'}\n",
    "social_words = {'friend', 'family', 'talk', 'meet', 'chat', 'parent', 'child', 'relationship', 'people'}\n",
    "temporal_words = {'today', 'now', 'soon', 'tomorrow', 'yesterday', 'later', 'always', 'never', 'before', 'after'}\n",
    "certainty = {'always', 'never', 'definitely', 'certain', 'sure'}\n",
    "negation = {'no', 'not', 'never', 'none', 'nobody'}\n",
    "\n",
    "# Function to extract LIWC-like features\n",
    "def extract_liwc_features(text):\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    \n",
    "    # Initialize counters for each category\n",
    "    pronoun_count = 0\n",
    "    function_word_count = 0\n",
    "    positive_emotion_count = 0\n",
    "    negative_emotion_count = 0\n",
    "    cognitive_process_count = 0\n",
    "    social_word_count = 0\n",
    "    temporal_word_count = 0\n",
    "    certainty_count = 0\n",
    "    negation_count = 0\n",
    "    \n",
    "    # Loop through each word in the text\n",
    "    for word in words:\n",
    "        word = word.lower()  # Normalize to lowercase\n",
    "        if word in pronouns:\n",
    "            pronoun_count += 1\n",
    "        if word in function_words:\n",
    "            function_word_count += 1\n",
    "        if word in positive_emotions:\n",
    "            positive_emotion_count += 1\n",
    "        if word in negative_emotions:\n",
    "            negative_emotion_count += 1\n",
    "        if word in cognitive_processes:\n",
    "            cognitive_process_count += 1\n",
    "        if word in social_words:\n",
    "            social_word_count += 1\n",
    "        if word in temporal_words:\n",
    "            temporal_word_count += 1\n",
    "        if word in certainty:\n",
    "            certainty_count += 1\n",
    "        if word in negation:\n",
    "            negation_count += 1\n",
    "    \n",
    "    # Calculate percentages relative to total word count\n",
    "    pronoun_percentage = pronoun_count / num_words if num_words > 0 else 0\n",
    "    function_word_percentage = function_word_count / num_words if num_words > 0 else 0\n",
    "    positive_emotion_percentage = positive_emotion_count / num_words if num_words > 0 else 0\n",
    "    negative_emotion_percentage = negative_emotion_count / num_words if num_words > 0 else 0\n",
    "    cognitive_process_percentage = cognitive_process_count / num_words if num_words > 0 else 0\n",
    "    social_word_percentage = social_word_count / num_words if num_words > 0 else 0\n",
    "    temporal_word_percentage = temporal_word_count / num_words if num_words > 0 else 0\n",
    "    certainty_percentage = certainty_count / num_words if num_words > 0 else 0\n",
    "    negation_percentage = negation_count / num_words if num_words > 0 else 0\n",
    "    \n",
    "    # Return a feature vector\n",
    "    return np.array([num_words, pronoun_percentage, function_word_percentage, \n",
    "                     positive_emotion_percentage, negative_emotion_percentage,\n",
    "                     cognitive_process_percentage, social_word_percentage, \n",
    "                     temporal_word_percentage, certainty_percentage, negation_percentage])\n",
    "\n",
    "# Apply the function to the dataset\n",
    "X_train_liwc = np.array([extract_liwc_features(text) for text in X_train])\n",
    "X_test_liwc = np.array([extract_liwc_features(text) for text in X_test])\n",
    "\n",
    "# Combine TF-IDF features, Word2Vec features, and LIWC-like features\n",
    "X_train_combined = hstack([X_train_tfidf, np.hstack((X_train_w2v, X_train_liwc))])\n",
    "X_test_combined = hstack([X_test_tfidf, np.hstack((X_test_w2v, X_test_liwc))])\n",
    "\n",
    "# Train and evaluate the model\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svc_model.fit(X_train_combined, y_train)\n",
    "y_pred_combined = svc_model.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report with LIWC-like Features:\")\n",
    "print(classification_report(y_test, y_pred_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f6995",
   "metadata": {},
   "source": [
    "# Weighting outperformed classes 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17489d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.95      0.61       770\n",
      "           1       0.40      0.03      0.06       819\n",
      "           2       0.99      0.91      0.95       671\n",
      "           3       1.00      0.94      0.96       687\n",
      "\n",
      "    accuracy                           0.68      2947\n",
      "   macro avg       0.71      0.71      0.65      2947\n",
      "weighted avg       0.69      0.68      0.62      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use TF-IDF Vectorizer to get unigram and bigram features\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Get the list of features (words or n-grams)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Extract features specific to class 0 (happy) and class 1 (sad)\n",
    "happy_indices = y_train == 0\n",
    "sad_indices = y_train == 1\n",
    "\n",
    "# Calculate the average TF-IDF scores for happy and sad songs\n",
    "happy_tfidf_avg = X_train_tfidf[happy_indices].mean(axis=0)\n",
    "sad_tfidf_avg = X_train_tfidf[sad_indices].mean(axis=0)\n",
    "\n",
    "# Identify unique features for happy and sad songs\n",
    "happy_unique_indices = np.where(happy_tfidf_avg > sad_tfidf_avg)[1]\n",
    "sad_unique_indices = np.where(sad_tfidf_avg > happy_tfidf_avg)[1]\n",
    "\n",
    "# Assign higher weights to these unique features\n",
    "X_train_weighted = X_train_tfidf.copy()\n",
    "X_train_weighted[:, happy_unique_indices] *= 1.5  \n",
    "X_train_weighted[:, sad_unique_indices] *= 1.5  \n",
    "##When try to increase weight more than 1.5 performance drops.\n",
    "# Train the SVM model with weighted features\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svc_model.fit(X_train_weighted, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "X_test_weighted = X_test_tfidf.copy()\n",
    "X_test_weighted[:, happy_unique_indices] *= 1.5\n",
    "X_test_weighted[:, sad_unique_indices] *= 1.5\n",
    "\n",
    "y_pred_weighted = svc_model.predict(X_test_weighted)\n",
    "print(classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f9a972",
   "metadata": {},
   "source": [
    "# GloVe SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f25eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Path to your GloVe file (300d vectors)\n",
    "glove_file = 'D:/glove.6B.300d.txt'\n",
    "\n",
    "# Initialize an empty dictionary to store embeddings\n",
    "glove_embeddings = {}\n",
    "\n",
    "# Load GloVe embeddings\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "print(f\"Loaded {len(glove_embeddings)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34af5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with GloVe embeddings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03       842\n",
      "           1       0.45      1.00      0.62       779\n",
      "           2       1.00      0.89      0.94       632\n",
      "           3       1.00      0.95      0.97       676\n",
      "\n",
      "    accuracy                           0.68      2929\n",
      "   macro avg       0.86      0.71      0.64      2929\n",
      "weighted avg       0.85      0.68      0.60      2929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_average_glove(text, embeddings, vector_size=300):\n",
    "    words = text.split()\n",
    "    word_vectors = [embeddings[word] for word in words if word in embeddings]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        # Return a vector of zeros if no valid words found\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "X_train_glove = np.array([get_average_glove(text, glove_embeddings) for text in X_train])\n",
    "X_test_glove = np.array([get_average_glove(text, glove_embeddings) for text in X_test])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_glove_scaled = scaler.fit_transform(X_train_glove)\n",
    "X_test_glove_scaled = scaler.transform(X_test_glove)\n",
    "\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svc_model.fit(X_train_glove_scaled, y_train)\n",
    "\n",
    "y_pred = svc_model.predict(X_test_glove_scaled)\n",
    "print(\"Classification Report with GloVe embeddings:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150273e9",
   "metadata": {},
   "source": [
    "# GloVe Combined Word2Vec SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c58bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Combined GloVe and Word2Vec embeddings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03       842\n",
      "           1       0.45      1.00      0.62       779\n",
      "           2       1.00      0.89      0.94       632\n",
      "           3       1.00      0.95      0.97       676\n",
      "\n",
      "    accuracy                           0.68      2929\n",
      "   macro avg       0.86      0.71      0.64      2929\n",
      "weighted avg       0.85      0.68      0.60      2929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Concatenate GloVe and Word2Vec embeddings\n",
    "X_train_combined = np.hstack([X_train_glove, X_train_w2v])\n",
    "X_test_combined = np.hstack([X_test_glove, X_test_w2v])\n",
    "\n",
    "# Step 3: Scale the combined embeddings\n",
    "scaler = StandardScaler()\n",
    "X_train_combined_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_test_combined_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# Step 4: Train the SVM model on the combined embeddings\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svc_model.fit(X_train_combined_scaled, y_train)\n",
    "\n",
    "# Step 5: Make predictions and evaluate the model\n",
    "y_pred_combined = svc_model.predict(X_test_combined_scaled)\n",
    "print(\"Classification Report with Combined GloVe and Word2Vec embeddings:\")\n",
    "print(classification_report(y_test, y_pred_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c4f392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Combined TF-IDF, GloVe, and Word2Vec embeddings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03       842\n",
      "           1       0.45      1.00      0.62       779\n",
      "           2       1.00      0.89      0.94       632\n",
      "           3       1.00      0.95      0.97       676\n",
      "\n",
      "    accuracy                           0.68      2929\n",
      "   macro avg       0.86      0.71      0.64      2929\n",
      "weighted avg       0.85      0.68      0.60      2929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_combined = np.hstack([X_train_tfidf.toarray(), X_train_glove, X_train_w2v])\n",
    "X_test_combined = np.hstack([X_test_tfidf.toarray(), X_test_glove, X_test_w2v])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_combined_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_test_combined_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "svc_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svc_model.fit(X_train_combined_scaled, y_train)\n",
    "\n",
    "y_pred_combined = svc_model.predict(X_test_combined_scaled)\n",
    "print(\"Classification Report with Combined TF-IDF, GloVe, and Word2Vec embeddings:\")\n",
    "print(classification_report(y_test, y_pred_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7d516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
